function J = autojacb(resd,x,opt,varargin)%AUTOGRAD numerical gradient%       Forward - forward differences%       Central - central differences (more accurate, but requires more %                 function evaluations)%       Complex - complex-step derivative (most accurate, but only works %                 for certain objective functions)defval('opt','Centered')nn = length(x);switch opt    case 'Centered'        mu = 2*sqrt(1e-12)*(1+norm(x));        delta1 = zeros(nn,1);        delta2 = zeros(nn,1);        for j = 1:nn            e_j = zeros(nn,1);            e_j(j) = 1;            delta1(:,j) = resd(x + mu*e_j, varargin{:});            delta2(:,j) = resd(x - mu*e_j, varargin{:});        end        end        J = (delta1 - delta2)/(2*mu);end