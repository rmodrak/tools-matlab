function g = autograd(fun,x,opt,varargin)%AUTOGRAD numerical gradient%       Forward - forward differences%       Central - central differences (more accurate, but requires more %                 function evaluations)%       Complex - complex-step derivative (most accurate, but only works %                 for certain objective functions)defval('opt','Centered')nn = length(x);switch opt    case 'Forward'        f = fun(x, varargin{:});        mu = 2*sqrt(1e-12)*(1+norm(x));        delta = zeros(nn,1);        for j = 1:nn            e_j = zeros(nn,1);            e_j(j) = 1;            delta(j,1) = fun(x + mu*e_j, varargin{:});        end        g = (delta-f)/mu;    case 'Centered'        mu = 2*sqrt(1e-12)*(1+norm(x));        delta1 = zeros(nn,1);        delta2 = zeros(nn,1);        for j = 1:nn            e_j = zeros(nn,1);            e_j(j) = 1;            delta1(j,1) = fun(x + mu*e_j, varargin{:});            delta2(j,1) = fun(x - mu*e_j, varargin{:});        end        f = mean([delta1;delta2]);        g = (delta1 - delta2)/(2*mu);    case 'Complex'        mu = 1e-150;        delta = zeros(nn,1);        for j = 1:nn            e_j = zeros(nn,1);            e_j(j) = 1;            delta(j,1) = fun(x + mu*1i*e_j, varargin{:});        end    	f = mean(real(delta));        g = imag(delta)/mu;end% print debugging informationif 0	[fReal gReal] = fun(x,varargin{:});	[fReal f]	[gReal g]	delta	pause;end